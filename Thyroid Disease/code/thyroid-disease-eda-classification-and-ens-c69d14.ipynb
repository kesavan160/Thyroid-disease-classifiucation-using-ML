{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Thyroid Disease EDA, Classification and Ensembling\n\nPredicting from the MLDataR package","metadata":{}},{"cell_type":"markdown","source":"The purpose of this notebook is to build my Data Sciece and Machine Learning skills. This is my third complete notebook. You can check other notebooks at my [github repository](https://github.com/elijahrona/Elijah-Rona-ML-Journey). Follow my everyday ML journey on [Twitter](https://twitter.com/elijah_rona).","metadata":{}},{"cell_type":"markdown","source":"## Loading Libraries","metadata":{}},{"cell_type":"code","source":"library(MLDataR) #Source of dataset\nlibrary(tidyverse) #EDA plus others\nlibrary(tidymodels) #Machine Leaning\nlibrary(skimr) #Data exploration\nlibrary(stacks) #Ensembling\nlibrary(ggpubr) #Plot arrangements","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-01-14T21:23:35.895293Z","iopub.execute_input":"2022-01-14T21:23:35.896811Z","iopub.status.idle":"2022-01-14T21:23:35.916685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading and Exploring the Dataset","metadata":{}},{"cell_type":"code","source":"df <- thyroid_disease #from the library\n\n#Let us explore the dataset\nskimmed <- skim(df)\nhead(skimmed)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:35.919034Z","iopub.execute_input":"2022-01-14T21:23:35.920432Z","iopub.status.idle":"2022-01-14T21:23:36.22734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df <- df[complete.cases(df),]\ndim(df)\nhead(df)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:36.229689Z","iopub.execute_input":"2022-01-14T21:23:36.231052Z","iopub.status.idle":"2022-01-14T21:23:36.26966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data looks okay and is ready for EDA and Modeling","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"Let us create a loop fuction to create several plots to help understand our data better","metadata":{}},{"cell_type":"code","source":"#Assign the variables\npredicator <- names(df)[2:27]\npredicator <- predicator[-c(1, 18, 20, 22, 24, 26)]\npredicator <- set_names(predicator)\nresponse <- names(df)[1]\nresponse <- set_names(response)\n\n#create loop function\nchart_fun <- function(x, y) {\n  ggplot(df, aes(fill=.data[[y]], x=as.factor(.data[[x]]))) + \n    geom_bar(position=\"dodge\", stat=\"count\", colour=\"black\") +\n    theme(\n      panel.background = element_rect(fill = \"white\",\n                                      colour = \"white\",\n                                      size = 0.5, linetype = \"solid\"))\n}\n\n#plot charts\nfinally <- map(response, ~map(predicator, chart_fun, y = .x))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:36.272657Z","iopub.execute_input":"2022-01-14T21:23:36.274136Z","iopub.status.idle":"2022-01-14T21:23:36.366986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us test the function if it works with the \"Pregnant\" column","metadata":{}},{"cell_type":"code","source":"library(repr) ;\noptions(repr.plot.width=16, repr.plot.height = 9)\nfinally$ThryroidClass$pregnant","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:36.369164Z","iopub.execute_input":"2022-01-14T21:23:36.370421Z","iopub.status.idle":"2022-01-14T21:23:36.698113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It works!! Time to combine all plots","metadata":{}},{"cell_type":"code","source":"cowplot::plot_grid(plotlist = finally[[1]], scale = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:36.700448Z","iopub.execute_input":"2022-01-14T21:23:36.701768Z","iopub.status.idle":"2022-01-14T21:23:41.021761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explaining these plots can be quite difficult, so let us use statistical EDA through which we can know if each column is effective in predicting the response column or not.\n\nNote that for the plots above, we only used columns with 1s and 0s (Just like the response column). The best form of stat EDA for such columns is chi-square. Note that if the P-Value is lower than 0.05, we will accept that the column is a good predicator.","metadata":{}},{"cell_type":"code","source":"chi_square_results <- purrr::map(df[,predicator[-c(16:20)]], ~chisq.test(.x, df$ThryroidClass))\nchi_square_results","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:41.024232Z","iopub.execute_input":"2022-01-14T21:23:41.025572Z","iopub.status.idle":"2022-01-14T21:23:41.176407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are many columns with P-Value lower than 0.05. This means that they are effective in predicting the response column. We, however, will use every column.\n\nTime to do EDA for the other normal continous columns","metadata":{}},{"cell_type":"code","source":"#get columns by index (You can call columns with this...)\npredicator1 <- names(df)[2:27]\npredicator1 <- predicator1[c(1, 18, 20, 22, 24, 26)]\npredicator1 <- set_names(predicator1)\n\nchart_fun1 <- function(x, y) {\n  ggplot(df, aes(y=.data[[x]], x=as.factor(.data[[y]]))) + \n    geom_boxplot(fill = 'bisque', color = 'black', alpha = 0.3) +\n    geom_jitter(aes(color = 'blue'), alpha = 0.2) +\n    guides(color = \"none\") +\n    theme_minimal() +\n    coord_cartesian(ylim = quantile(.data[[x]], c(0, 0.999)))\n}\n\nfinally1 <- map(response, ~map(predicator1, chart_fun1, y = .x))\n\ncowplot::plot_grid(plotlist = finally1[[1]])","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:41.181341Z","iopub.execute_input":"2022-01-14T21:23:41.183123Z","iopub.status.idle":"2022-01-14T21:23:43.404885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the boxplots that older people are more likely to have thyroid. To further understand all columns, let us use ANOVA. Same principle of P-Value applies here","metadata":{}},{"cell_type":"code","source":"anova_results <- purrr::map(df[,predicator1], ~summary(aov(.x ~ df$ThryroidClass)))\nanova_results","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:43.408457Z","iopub.execute_input":"2022-01-14T21:23:43.410705Z","iopub.status.idle":"2022-01-14T21:23:43.450068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we know which column is a good predicator and which is not, it is time to build our model","metadata":{}},{"cell_type":"markdown","source":"## Building Out Models\n### 1. Splitting Our Dataset","metadata":{}},{"cell_type":"code","source":"#Make sure that the response is a factor\ndf <- df %>%\n  mutate(ThryroidClass = as.factor(ThryroidClass))\n\n#split the dataset\nset.seed(123)\ntd_split  <- initial_split(df, \n                             strata = ThryroidClass,\n                             breaks = 4)\ntd_train  <- training(td_split)\ntd_test   <- testing(td_split)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:43.452406Z","iopub.execute_input":"2022-01-14T21:23:43.453781Z","iopub.status.idle":"2022-01-14T21:23:43.48737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Making a Recipe","metadata":{}},{"cell_type":"code","source":"td_recipe <- recipe(ThryroidClass ~ ., data = td_train) %>% #Set the formula\n  remove_role(ref_src, old_role = \"predictor\") %>% #We do not want to use the \"ref_src\" column\n  step_normalize(all_numeric_predictors()) %>% #Normalize every numeric predicator\n  step_zv(all_predictors()) #Remove predicators with only one value (they are useless)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:43.489629Z","iopub.execute_input":"2022-01-14T21:23:43.490918Z","iopub.status.idle":"2022-01-14T21:23:43.543436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us test the recipe","metadata":{}},{"cell_type":"code","source":"rec_sam <- td_recipe %>% \n  prep(training = td_train, retain = TRUE) %>% #so_train is train data\n  juice()\n\nhead(rec_sam)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:43.545871Z","iopub.execute_input":"2022-01-14T21:23:43.547276Z","iopub.status.idle":"2022-01-14T21:23:43.682039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset above is exactly what out recipe produced. This is what we will train our model with","metadata":{}},{"cell_type":"markdown","source":"### 3 (A). Training a Model (Random Forest-Ranger)","metadata":{}},{"cell_type":"code","source":"#Specify the model and mode\ntd_rf <-\n  rand_forest() %>%\n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n\n#Make a workflow. We add the recipe we creatd earlier\ntd_rf_wf <- \n  workflow() %>% \n  add_recipe(td_recipe) %>% \n  add_model(td_rf)\n\n# Fit Model\nset.seed(234)\ntd_rf_fit <- \n  td_rf_wf %>% \n  fit(data = td_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:43.684275Z","iopub.execute_input":"2022-01-14T21:23:43.68557Z","iopub.status.idle":"2022-01-14T21:23:44.503448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us predict with our test data","metadata":{}},{"cell_type":"code","source":"td_rf_pred <- augment(td_rf_fit, td_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:44.505718Z","iopub.execute_input":"2022-01-14T21:23:44.507003Z","iopub.status.idle":"2022-01-14T21:23:44.643882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3 (B). Evaluating Our Model (Random Forest=Ranger)","metadata":{}},{"cell_type":"code","source":"td_rf_pred %>%\n  roc_auc(truth = ThryroidClass, \n            estimate = .pred_negative)\n\ntd_rf_pred %>%\n  roc_curve(truth = ThryroidClass, \n            estimate = .pred_negative) %>% \n  autoplot()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:44.646177Z","iopub.execute_input":"2022-01-14T21:23:44.647525Z","iopub.status.idle":"2022-01-14T21:23:44.933653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Roc_AUC is wonderful","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"caret::confusionMatrix(reference = td_rf_pred$ThryroidClass, data = td_rf_pred$.pred_class, mode='everything', positive='sick')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:23:44.935881Z","iopub.execute_input":"2022-01-14T21:23:44.937293Z","iopub.status.idle":"2022-01-14T21:23:44.955563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With an accuracy of 98%, this model is almost perfect. Well, let us try other models","metadata":{}},{"cell_type":"markdown","source":"### 4 (A). Building Our Model (XGBOOST)","metadata":{}},{"cell_type":"markdown","source":"#We will be tuning this model","metadata":{}},{"cell_type":"code","source":"#Get the tuning parameters of a model\nargs(boost_tree)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:28:35.20492Z","iopub.execute_input":"2022-01-14T21:28:35.206707Z","iopub.status.idle":"2022-01-14T21:28:35.224598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Specify the model\ntd_xgboost <- boost_tree(trees = tune(), tree_depth = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\")\n\n#Set the selected tuning parameters in grid\nboost_grid <- grid_regular( #chooses sensible values to try for each hyperparameter\n  trees(), tree_depth(),levels = 5)\n\n#Create folds\nset.seed(234)\nfolds <- vfold_cv(td_train)\n\n#Add model and recipe to workflow\ntd_xgboost_wf <- workflow() %>%\n  add_model(td_xgboost) %>%\n  add_recipe(td_recipe)\n\n#Start testing different parameters in different grids according to the settings\nset.seed(124)\ntd_xgboost_fold <- td_xgboost_wf %>% \n  tune_grid(resamples = folds, grid = boost_grid)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:30:07.723914Z","iopub.execute_input":"2022-01-14T21:30:07.725681Z","iopub.status.idle":"2022-01-14T21:32:49.700758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What is the best hyperparameter combination?","metadata":{}},{"cell_type":"code","source":"head(collect_metrics(td_xgboost_fold))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:33:10.393518Z","iopub.execute_input":"2022-01-14T21:33:10.39506Z","iopub.status.idle":"2022-01-14T21:33:10.446791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_boost <- td_xgboost_fold %>%\n  select_best(\"accuracy\")\n\nbest_boost","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:33:17.004411Z","iopub.execute_input":"2022-01-14T21:33:17.005986Z","iopub.status.idle":"2022-01-14T21:33:17.067039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us visualize the varirous hyperparameters used","metadata":{}},{"cell_type":"code","source":"td_xgboost_fold %>%\n  collect_metrics() %>%\n  mutate(tree_depth = factor(tree_depth)) %>%\n  ggplot(aes(trees, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:33:45.612221Z","iopub.execute_input":"2022-01-14T21:33:45.613853Z","iopub.status.idle":"2022-01-14T21:33:46.260583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we saved the best hyperparameter combination as \"best_boost\", we will use that variable in out model","metadata":{}},{"cell_type":"code","source":"#Using the best hyperparameters\nfinal_xgboost_wf <- \n  td_xgboost_wf %>% \n  finalize_workflow(best_boost)\n\n#Fitting out model\nfinal_xgboost_fit <- \n  final_xgboost_wf %>%\n  last_fit(td_split) #last_fit trains with train data and tests test data automatically","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:35:29.805564Z","iopub.execute_input":"2022-01-14T21:35:29.807528Z","iopub.status.idle":"2022-01-14T21:35:30.627635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4 (B). Evaluating Our Model (XGBOOST)","metadata":{}},{"cell_type":"code","source":"collect_metrics(final_xgboost_fit)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:36:31.843931Z","iopub.execute_input":"2022-01-14T21:36:31.846523Z","iopub.status.idle":"2022-01-14T21:36:31.872451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good accuracy","metadata":{}},{"cell_type":"code","source":"final_xgboost_fit %>% #You can use this to predict on new data\n  collect_predictions() %>% \n  roc_curve(ThryroidClass, .pred_negative) %>% \n  autoplot()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:37:12.556055Z","iopub.execute_input":"2022-01-14T21:37:12.557656Z","iopub.status.idle":"2022-01-14T21:37:12.85291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us predict with our test dataset","metadata":{}},{"cell_type":"code","source":"#Collect predictions\ntd_xgboost_pred <- final_xgboost_fit %>% #You can use this to predict on new data\n  collect_predictions()\n\n#Add the predictions to our testdata set\ntd_xgboost_pred <- cbind(td_test, td_xgboost_pred)\n\nhead(td_xgboost_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:38:19.284947Z","iopub.execute_input":"2022-01-14T21:38:19.28665Z","iopub.status.idle":"2022-01-14T21:38:19.343829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion matrix\ncaret::confusionMatrix(reference = td_xgboost_pred$ThryroidClass, data = td_xgboost_pred$.pred_class, mode='everything', positive='sick')","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:38:42.60103Z","iopub.execute_input":"2022-01-14T21:38:42.602775Z","iopub.status.idle":"2022-01-14T21:38:42.623692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensembling Models","metadata":{}},{"cell_type":"markdown","source":"I love ensembling because I love seeing people and machines working together","metadata":{}},{"cell_type":"markdown","source":"### 1. Grid and Resample","metadata":{}},{"cell_type":"code","source":"ctrl_grid <- stacks::control_stack_grid() #Get the grid function (best for xgboost because we tuned it)\nctrl_res <- stacks::control_stack_resamples() #Get the resamples function (best for random forest because we did not tune it)\n\nmetric <- metric_set(accuracy, roc_auc)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:40:43.313116Z","iopub.execute_input":"2022-01-14T21:40:43.315051Z","iopub.status.idle":"2022-01-14T21:40:43.335835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Setting Our Models for Tuning","metadata":{}},{"cell_type":"markdown","source":"XGBOOST","metadata":{}},{"cell_type":"code","source":"xgboost_res <- \n  tune_grid(\n    td_xgboost_wf,\n    resamples = folds,\n    metrics = metric,\n    grid = 4,\n    control = ctrl_grid\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:42:03.384568Z","iopub.execute_input":"2022-01-14T21:42:03.386514Z","iopub.status.idle":"2022-01-14T21:43:26.391409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest","metadata":{}},{"cell_type":"code","source":"rf_res <- \n  fit_resamples(\n    td_rf_wf, #workflow\n    resamples = folds, #cvfold\n    metrics = metric,\n    control = ctrl_res\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:43:26.395176Z","iopub.execute_input":"2022-01-14T21:43:26.39676Z","iopub.status.idle":"2022-01-14T21:43:36.107012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Time to Add Our Models","metadata":{}},{"cell_type":"code","source":"set.seed(234)\nmodel_data_st <-  stacks() %>%\n  add_candidates(xgboost_res) %>%\n  add_candidates(rf_res)\n\nhead(model_data_st)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:43:36.110238Z","iopub.execute_input":"2022-01-14T21:43:36.111695Z","iopub.status.idle":"2022-01-14T21:43:38.339478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Blending Our Models' Predictions","metadata":{}},{"cell_type":"code","source":"#Blend the predictions\nset.seed(148)\nfitted_model_st <-\n  model_data_st %>%\n  blend_predictions()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us visualize the fitted models","metadata":{}},{"cell_type":"code","source":"autoplot(fitted_model_st)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:43:46.703799Z","iopub.execute_input":"2022-01-14T21:43:46.705566Z","iopub.status.idle":"2022-01-14T21:43:47.161064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our ensembled model will select the best penalty and other parameters\n","metadata":{}},{"cell_type":"markdown","source":"### 5. Ensembling the Models","metadata":{}},{"cell_type":"code","source":"#Ensemble models\nset.seed(111)\nfitted_model_st <-\n  fitted_model_st %>%\n  fit_members()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:44:53.896481Z","iopub.execute_input":"2022-01-14T21:44:53.898242Z","iopub.status.idle":"2022-01-14T21:44:55.791394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time to predict with the test data","metadata":{}},{"cell_type":"code","source":"#predict test data\ntest_predict_data <- \n  td_test %>%\n  bind_cols(predict(fitted_model_st, .))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:45:24.644181Z","iopub.execute_input":"2022-01-14T21:45:24.645728Z","iopub.status.idle":"2022-01-14T21:45:24.784371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(test_predict_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:45:26.893367Z","iopub.execute_input":"2022-01-14T21:45:26.895129Z","iopub.status.idle":"2022-01-14T21:45:26.9271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Comparing our Models","metadata":{}},{"cell_type":"code","source":"#Compare ensembled with members\nmember_preds <- \n  test_predict_data %>%\n  select(ThryroidClass) %>%\n  bind_cols(predict(fitted_model_st, td_test, members = TRUE))\n\nmap_dfr(member_preds, accuracy, truth = ThryroidClass, data = member_preds) %>%\n  mutate(member = colnames(member_preds))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:45:53.566159Z","iopub.execute_input":"2022-01-14T21:45:53.568066Z","iopub.status.idle":"2022-01-14T21:45:54.221627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"They all seem good","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"markdown","source":"It elps to visualize our predicted data (in relation to the truth)","metadata":{}},{"cell_type":"code","source":"p1 <- conf_mat(td_rf_pred, truth = ThryroidClass, estimate = .pred_class) %>% \n  autoplot(type = \"heatmap\") +\n  labs(title = \"Random Forest Alone\")\n\ntd_xgboost_pred <- td_xgboost_pred[,-1]\np2 <- conf_mat(td_xgboost_pred, truth = ThryroidClass, estimate = .pred_class) %>% \n  autoplot(type = \"heatmap\") +\n  labs(title = \"XGBOOST Alone\")\n\np3 <- conf_mat(member_preds, truth = ThryroidClass, estimate = .pred_class) %>% \n  autoplot(type = \"heatmap\") +\n  labs(title = \"Ensembled\")\n\np4 <- conf_mat(member_preds, truth = ThryroidClass, estimate = .pred_class_xgboost_res_1_2) %>% \n  autoplot(type = \"heatmap\") +\n  labs(title = \"XGBOOST in Ensembled\")\n\np5 <- conf_mat(member_preds, truth = ThryroidClass, estimate = .pred_class_rf_res_1_1) %>% \n  autoplot(type = \"heatmap\") +\n  labs(title = \"Random Forest in Ensembled\")\n\nggarrange(p1,p2,p3,p4,p5,\n          ncol = 3,\n          nrow = 2)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T21:47:40.611631Z","iopub.execute_input":"2022-01-14T21:47:40.613425Z","iopub.status.idle":"2022-01-14T21:47:41.591416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the matrix, do you thik that our models inproved after the ensembling? Share your thoughts.","metadata":{}},{"cell_type":"markdown","source":"## Thank You\n\nRemember that you can link with me on [Twitter](https://twitter.com/elijah_rona).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}